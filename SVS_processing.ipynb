{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuropoly/single_voxel_mrs_b0_shimming/blob/main/SVS_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hjCE6GLlTI7"
      },
      "source": [
        "# SVS processing - interactive notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnaT-VdNlTI-"
      },
      "source": [
        "This notebook demos the process of B0 shimmng and spectral fitting n case of a single voxel MRS data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfU21cYmlTI_"
      },
      "source": [
        "## Contents:\n",
        "\n",
        "1. [Install dependencies](#1.-Install-dependencies)\n",
        "2. [Import required libraries](#2.-Import-required-libraries)\n",
        "3. [Download the data](#3.-Download-the-data)\n",
        "4. [B0 Fieldmaps calculation](#4.-Compute-fieldmaps)\n",
        "5. [B0 shimming](#5.-Perform-B0-shimming-using-the-computed-filedmaps)\n",
        "6. [B0 Fieldmaps comparison](#6.-B0-Fieldmaps-comparison)\n",
        "7. [MRS analysis](#7.-MRS-analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phs6gCJ1lTI_"
      },
      "source": [
        "## 1. Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy_EGEgylTI_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "!git clone --recurse-submodules https://git.fmrib.ox.ac.uk/fsl/fsl_mrs.git\n",
        "%cd /content/fsl_mrs\n",
        "!pip install .\n",
        "\n",
        "%cd /content\n",
        "!git clone --single-branch --branch gradient_optimizer https://github.com/shimming-toolbox/shimming-toolbox.git\n",
        "%cd /content/shimming-toolbox/\n",
        "!pip install .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VxegHqgzUTm"
      },
      "outputs": [],
      "source": [
        "# Restart the runtime to resolve the compatibilty issues between the packages\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0IDwpEwlTJA"
      },
      "source": [
        "## 2. Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzNltv9jwoXz"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "import os\n",
        "os.environ[\"LD_PRELOAD\"] = \"\";\n",
        "os.environ[\"APPTAINER_BINDPATH\"] = \"/content\"\n",
        "os.environ[\"MPLCONFIGDIR\"] = \"/content/matplotlib-mpldir\"\n",
        "os.environ[\"LMOD_CMD\"] = \"/usr/share/lmod/lmod/libexec/lmod\"\n",
        "os.environ[\"MODULEPATH\"] = \"/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/molecular_biology:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/workflows:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/visualization:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/structural_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/statistics:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/spine:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/spectroscopy:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/shape_analysis:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/segmentation:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/rodent_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/quantitative_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/quality_control:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/programming:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/phase_processing:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/machine_learning:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/image_segmentation:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/image_registration:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/image_reconstruction:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/hippocampus:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/functional_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/electrophysiology:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/diffusion_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/data_organisation:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/body\"\n",
        "\n",
        "!curl -J -O https://raw.githubusercontent.com/NeuroDesk/neurocommand/main/googlecolab_setup.sh\n",
        "!chmod +x googlecolab_setup.sh\n",
        "!./googlecolab_setup.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fArgkjVwnurU",
        "outputId": "126f7f45-e757-4664-ea52-805970a2344e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fsl/6.0.4']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import lmod\n",
        "await lmod.load('fsl/6.0.4')\n",
        "await lmod.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q08UP-P5lTJB"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import datetime\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from IPython.display import HTML\n",
        "import fsl_mrs.utils.mrs_io as mrs_io\n",
        "from fsl_mrs.utils.preproc import nifti_mrs_proc as proc\n",
        "import fsl_mrs as mrs\n",
        "from fsl_mrs.utils import report, fitting, misc, plotting\n",
        "from shimmingtoolbox.prepare_fieldmap import prepare_fieldmap\n",
        "from shimmingtoolbox.load_nifti import read_nii\n",
        "from shimmingtoolbox.cli import b0shim\n",
        "from shimmingtoolbox.masking.threshold import threshold as mask_threshold\n",
        "\n",
        "try:\n",
        "    import nilearn\n",
        "    import seaborn as sns\n",
        "    import plotly.graph_objects as go\n",
        "    import plotly.io as pio\n",
        "\n",
        "except ImportError:\n",
        "    !pip install seaborn\n",
        "    import seaborn as sns\n",
        "    !pip install nilearn\n",
        "    import nilearn\n",
        "    import nilearn.image\n",
        "    !pip install plotly\n",
        "    import plotly.graph_objects as go\n",
        "    import plotly.io as pio\n",
        "!pip install statsmodels\n",
        "!pip install osfclient\n",
        "print('Necessary libraries are imported')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEuAWZjBlTJB"
      },
      "source": [
        "## 3. Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWe7aUwCt4G3"
      },
      "outputs": [],
      "source": [
        "!osf -p s3gwv fetch /SVS_MRS_DATA.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VUS0SmWlTJC"
      },
      "outputs": [],
      "source": [
        "# Unzip the data\n",
        "zipped_data = \"/content/\" + \"SVS_MRS_DATA.zip\"\n",
        "with zipfile.ZipFile(zipped_data,\"r\") as zipfile:\n",
        "  zipfile.extractall('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ovVOFv1ve2J"
      },
      "source": [
        "## 4. Compute fieldmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U5h7uEJlTJD"
      },
      "outputs": [],
      "source": [
        "if os.path.basename(os.getcwd()) != 'SVS_MRS_DATA':\n",
        "    os.chdir(os.getcwd()+'/SVS_MRS_DATA/')\n",
        "\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "shim_methods=['siemens','pi' ,'quadprog' ,'lsq','grad']\n",
        "subjects_list = [name for name in os.listdir() if os.path.isdir(name) and name.startswith('sub')]\n",
        "subjects_list.sort(key=lambda x: int(x.split('-')[1]))\n",
        "print(subjects_list)\n",
        "\n",
        "# Iterate over each subject\n",
        "for subject in subjects_list:\n",
        "    derivative_path = current_path + f\"/derivatives/{subject}/\"\n",
        "    fmap_path = f\"{derivative_path}fmap/\"\n",
        "    if not os.path.exists(fmap_path):\n",
        "        os.makedirs(fmap_path)\n",
        "\n",
        "    mask_mrs_nii = nib.load(derivative_path + 'mask_mrs.nii.gz')\n",
        "    mask_mrs = mask_mrs_nii.get_fdata()\n",
        "    mask_anat_nii = nib.load (derivative_path + 'bet_anat_mask.nii.gz')\n",
        "\n",
        "    # Iterate over each shim method\n",
        "    for method in shim_methods:\n",
        "\n",
        "        # Load the file corresponding to the method\n",
        "        gre_path =  current_path + f\"/{subject}/fmap/\"\n",
        "        mag = read_nii(gre_path + f\"{subject}_acq-{method}Shim_magnitude1.nii.gz\")\n",
        "        phase1 = read_nii(gre_path + f\"{subject}_acq-{method}Shim_phase1.nii.gz\", auto_scale=True)\n",
        "        phase2 = read_nii(gre_path + f\"{subject}_acq-{method}Shim_phase2.nii.gz\", auto_scale=True)\n",
        "\n",
        "        # Load JSON data from the magnitude nifti\n",
        "        with open(gre_path + f\"{subject}_acq-{method}Shim_magnitude1.json\", 'r') as mag_json:\n",
        "            json_data = json.load(mag_json)\n",
        "\n",
        "        phase_list_data = [phase1[2], phase2[2]]\n",
        "\n",
        "        # scale the phase data to (-pi, pi) range\n",
        "        scaled_phase_list_data = [((phase_list_data[i] - np.min(phase_list_data[i]))/(np.max(phase_list_data[i])-np.min(phase_list_data[i])))\n",
        "                             *2*np.pi-np.pi for i in range(len(phase_list_data))]\n",
        "        # convert to nifti\n",
        "        scaled_phase_list_nii = [nib.Nifti1Image(scaled_phase_list_data[i], phase1[0].affine, phase1[0].header)\n",
        "                             for i in range(len(scaled_phase_list_data))]\n",
        "\n",
        "        EchoTime1 = phase1[1]['EchoTime']\n",
        "        EchoTime2 = phase2[1]['EchoTime']\n",
        "        echo_times = [EchoTime1, EchoTime2]\n",
        "\n",
        "        # compute fieldmap for each method\n",
        "        fieldmap = prepare_fieldmap(scaled_phase_list_nii, echo_times, mag[2], unwrapper='prelude', gaussian_filter= True, nii_mask= mask_anat_nii, sigma=0.5)\n",
        "        # store the fieldmap under the corresponding path\n",
        "        fieldmap_nii = nib.Nifti1Image(fieldmap[0], phase1[0].affine, phase1[0].header )\n",
        "        nib.save(fieldmap_nii, fmap_path + f\"{subject}_acq-{method}-fieldmap.nii.gz\")\n",
        "\n",
        "        # store the corresponding json file for each fieldmap\n",
        "        with open(fmap_path + f\"{subject}_acq-{method}-fieldmap.json\", 'w') as fmap_json:\n",
        "            json.dump(json_data, fmap_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEYGsih_ZXKs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "# Create a figure with a specific size and white background\n",
        "fig = plt.figure(figsize=(12, 5), facecolor='white')\n",
        "plt.suptitle('Grad fieldmap (Hz)', fontsize=16, fontweight='bold')\n",
        "# Define gridspec\n",
        "gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 0.8])\n",
        "\n",
        "# Plot sagittal cut\n",
        "ax1 = plt.subplot(gs[0])\n",
        "ax1.imshow(np.rot90(fieldmap[0][30,:,:]), vmin=-100, vmax=100, cmap='jet')\n",
        "ax1.set_xticks([])  # Turn off x-axis ticks\n",
        "ax1.set_yticks([])  # Turn off y-axis ticks\n",
        "ax1.set_title('Sagittal', fontsize=12)\n",
        "\n",
        "# Plot coronal cut\n",
        "ax2 = plt.subplot(gs[1])\n",
        "ax2.imshow(np.rot90(fieldmap[0][:,34,:]), vmin=-100, vmax=100,  cmap='jet')\n",
        "ax2.set_xticks([])  # Turn off x-axis ticks\n",
        "ax2.set_yticks([])  # Turn off y-axis ticks\n",
        "ax2.set_title('Coronal', fontsize=12)\n",
        "\n",
        "# Plot axial cut\n",
        "ax3 = plt.subplot(gs[2])\n",
        "img = ax3.imshow(np.rot90(fieldmap[0][...,6]), vmin=-100, vmax=100,  cmap='jet')\n",
        "ax3.set_xticks([])  # Turn off x-axis ticks\n",
        "ax3.set_yticks([])  # Turn off y-axis ticks\n",
        "ax3.set_title('Axial', fontsize=12)\n",
        "cbar = plt.colorbar(img, ax=ax3)  # Add color bar\n",
        "cbar.ax.tick_params(labelsize=20)  # Set font size for color bar\n",
        "\n",
        "# Save the figure with 300 dpi\n",
        "plt.savefig('fieldmap_example.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyXMxQD_kuYY"
      },
      "source": [
        "## 5. Perform B0 shimming using the computed filedmaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPD9rF_mZXKt"
      },
      "source": [
        "### 5.1 Shimming on whole brain mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNQZjXnTkuYY"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Generate subjects list as an array\n",
        "subjects_list=$(find .  -type d -maxdepth 1 -name \"sub-*\"| sort -V)\n",
        "IFS=$'\\n' read -d '' -r -a subjects_array <<< \"$subjects_list\"\n",
        "echo \"subjects list are: $subjects_list\"\n",
        "\n",
        "path_derivatives=$(find . -type d -name derivatives)\n",
        "shim_methods=(\"pi\" \"quadprog\" \"lsq\" \"grad\")\n",
        "for method in \"${shim_methods[@]}\"; do\n",
        "\n",
        "    # Create a file to store the time taken for each method\n",
        "    time_file=\"${path_derivatives}/All_subjects/${method}_whole_Brain_time.txt\"\n",
        "\n",
        "    for subject in \"${subjects_array[@]}\"; do\n",
        "        echo \"Subject: $subject\"\n",
        "        echo \"Method: $method\"\n",
        "        subject_name=$(basename \"$subject\")\n",
        "        fmap_path=${path_derivatives}/${subject_name}\n",
        "        mask=$(find ${fmap_path} -type f -name \"bet_anat_mask.nii.gz\")\n",
        "        output_grad=\"${fmap_path}/fmap/static_shim_grad/Whole_brian_mask\"\n",
        "        output_lsq=\"${fmap_path}/fmap/static_shim_lsq/Whole_brian_mask\"\n",
        "        output_pi=\"${fmap_path}/fmap/static_shim_pi/Whole_brian_mask\"\n",
        "        output_quadprog=\"${fmap_path}/fmap/static_shim_quadprog/Whole_brian_mask\"\n",
        "\n",
        "        fieldmap=$(find ${path_derivatives}/${subject_name}/fmap -type f -name \"${subject_name}_acq-${method}-fieldmap.nii.gz\")\n",
        "        echo $fieldmap\n",
        "\n",
        "        if [ \"${method}\" = \"lsq\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\"  --optimizer-method \"least_squares\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_lsq}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"grad\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\"  --optimizer-method \"gradient\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_grad}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"pi\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-method \"pseudo_inverse\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_pi}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"quadprog\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-method \"quad_prog\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_quadprog}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        fi\n",
        "    done\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI7IqH8cZXKt"
      },
      "outputs": [],
      "source": [
        "def calculate_average(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        times = [float(line.strip()) for line in file]\n",
        "        return sum(times) / len(times)\n",
        "\n",
        "path = current_path+\"/derivatives/All_subjects\"\n",
        "shim_methods = [\"pi\", \"quadprog\", \"lsq\", \"grad\"]\n",
        "\n",
        "for method in shim_methods:\n",
        "    file_path = os.path.join(path, f\"{method}_whole_Brain_time.txt\")\n",
        "    if os.path.exists(file_path):\n",
        "        average_time = calculate_average(file_path)\n",
        "        print(f\"Average computation time for {method} in whole Brain: {average_time} seconds\")\n",
        "    else:\n",
        "        print(f\"File not found for {method}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNAzMiErZXKt"
      },
      "source": [
        "### 5.2 Shimming on MRS voxel location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WSOyK-yZXKu"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Generate subjects list as an array\n",
        "subjects_list=$(find .  -type d -maxdepth 1 -name \"sub-*\"| sort -V)\n",
        "IFS=$'\\n' read -d '' -r -a subjects_array <<< \"$subjects_list\"\n",
        "echo \"subjects list are: $subjects_list\"\n",
        "\n",
        "path_derivatives=$(find . -type d -name derivatives)\n",
        "shim_methods=(\"pi\" \"quadprog\" \"lsq\" \"grad\")\n",
        "for method in \"${shim_methods[@]}\"; do\n",
        "\n",
        "    # Create a file to store the time taken for each method\n",
        "    time_file=\"${path_derivatives}/All_subjects/${method}_MRS_mask_time.txt\"\n",
        "\n",
        "    for subject in \"${subjects_array[@]}\"; do\n",
        "        echo \"Subject: $subject\"\n",
        "        echo \"Method: $method\"\n",
        "        subject_name=$(basename \"$subject\")\n",
        "        fmap_path=${path_derivatives}/${subject_name}\n",
        "        mask=$(find ${fmap_path} -type f -name \"mask_mrs.nii.gz\")\n",
        "        output_grad=\"${fmap_path}/fmap/static_shim_grad/MRS_mask\"\n",
        "        output_lsq=\"${fmap_path}/fmap/static_shim_lsq/MRS_mask\"\n",
        "        output_pi=\"${fmap_path}/fmap/static_shim_pi/MRS_mask\"\n",
        "        output_quadprog=\"${fmap_path}/fmap/static_shim_quadprog/MRS_mask\"\n",
        "\n",
        "        fieldmap=$(find ${path_derivatives}/${subject_name}/fmap -type f -name \"${subject_name}_acq-${method}-fieldmap.nii.gz\")\n",
        "        echo $fieldmap\n",
        "\n",
        "        if [ \"${method}\" = \"lsq\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\"  --optimizer-method \"least_squares\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_lsq}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"grad\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\"  --optimizer-method \"gradient\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_grad}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"pi\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-method \"pseudo_inverse\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_pi}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"quadprog\" ]; then\n",
        "            { time -p st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-method \"quad_prog\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_quadprog}\"; } 2>&1 | grep real | cut -d' ' -f2 >> \"${time_file}\" || exit\n",
        "\n",
        "        fi\n",
        "    done\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo8ZMIXxZXKu"
      },
      "outputs": [],
      "source": [
        "def calculate_average(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        times = [float(line.strip()) for line in file]\n",
        "        return sum(times) / len(times)\n",
        "\n",
        "path = current_path+\"/derivatives/All_subjects\"\n",
        "shim_methods = [\"pi\", \"quadprog\", \"lsq\", \"grad\"]\n",
        "\n",
        "for method in shim_methods:\n",
        "    file_path = os.path.join(path, f\"{method}_MRS_mask_time.txt\")\n",
        "    if os.path.exists(file_path):\n",
        "        average_time = calculate_average(file_path)\n",
        "        print(f\"Average computation time for {method} in MRS mask: {average_time} seconds\")\n",
        "    else:\n",
        "        print(f\"File not found for {method}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0qCBPnAlTJD"
      },
      "source": [
        "## 6. B0 Fieldmaps comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoEPEgcgkuYY"
      },
      "source": [
        "### 6.1 Function to analyze the fieldmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMkUSY6K0T7j"
      },
      "outputs": [],
      "source": [
        "def analyse_fieldmap(source_dir, labels, fieldmaps, output, mask, subject, roi_name, fig_size):\n",
        "    \"\"\"\n",
        "    Description: Generates a violin plot representing the distribution of the given fieldmaps\n",
        "    labels: List of strings including fieldmaps label\n",
        "    fieldmaps: List of numpy arrays of fieldmaps in the same order as labels\n",
        "    output: Output folder to save the violin plot\n",
        "    mask: Numpy array of a Mask corresponding to the MRS voxel volume\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=fig_size)\n",
        "    sns.set(font_scale=2)\n",
        "\n",
        "    output_path = os.path.join(source_dir, output)\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    if np.shape(mask)==np.shape(fieldmaps[0]):\n",
        "        dict_map_avg = {label: fieldmap[mask == 1] for label, fieldmap in zip(labels, fieldmaps)}\n",
        "    else:\n",
        "        dict_map_avg = {label: fieldmap for label, fieldmap in zip(labels, fieldmaps)}\n",
        "\n",
        "    def calculate_rmse(data):\n",
        "        mse = np.mean(np.square(data))\n",
        "        rmse = np.sqrt(mse)\n",
        "        return rmse\n",
        "\n",
        "    dict_means = {key: np.round(np.mean(value), 1) for key, value in dict_map_avg.items()}\n",
        "    dict_stds = {key: np.round(np.std(value), 1) for key, value in dict_map_avg.items()}\n",
        "    dict_rmse = {key: calculate_rmse(value) for key, value in dict_map_avg.items()}\n",
        "\n",
        "    ax = sns.violinplot(data=list(dict_map_avg.values()))\n",
        "\n",
        "    for i, (key, mean) in enumerate(dict_means.items()):\n",
        "        mean_str = \"{:.1f}\".format(mean)\n",
        "        std_str = \"{:.1f}\".format(dict_stds[key])\n",
        "        rmse_str = \"{:.1f}\".format(dict_rmse[key])\n",
        "        ax.text(i + 0.05, 0, f\"Mean: {mean_str}\\nSD: {std_str}\\nRMSE: {rmse_str}\",\n",
        "                horizontalalignment='left', verticalalignment='top', fontsize=70 / len(dict_means))\n",
        "\n",
        "    ax.set_ylabel('Frequency [Hz]', fontsize=60 / len(dict_means), fontweight='bold')\n",
        "    ax.set_xticks(range(len(labels)))\n",
        "    ax.set_xticklabels(labels, fontsize=60 / len(dict_means), fontweight='bold', rotation=45)\n",
        "    ax.set_title(f\"{subject}: $\\Delta$B0 distribution_within_{roi_name}_mask\", fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.tick_params(axis='y', labelsize=10)\n",
        "    plt.savefig(os.path.join(output_path, f\"{subject}_B0_distribution_within_{roi_name}_mask.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    return dict_stds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWQO-9gCkuYZ"
      },
      "source": [
        "### 6.2 Display the fieldmaps distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3PaAVHKZXKv"
      },
      "source": [
        "#### 6.2.1 Shimming on whole brain mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i42xT9qHlTJD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from nilearn import image\n",
        "all_Grad_fmaps_whole_brain_shimmed=[]\n",
        "all_PI_fmaps_whole_brain_shimmed=[]\n",
        "all_LSq_fmaps_whole_brain_shimmed=[]\n",
        "all_QuadProg_fmaps_whole_brain_shimmed=[]\n",
        "\n",
        "all_Grad_fmaps_whole_brain_unshimmed=[]\n",
        "all_PI_fmaps_whole_brain_unshimmed=[]\n",
        "all_LSq_fmaps_whole_brain_unshimmed=[]\n",
        "all_QuadProg_fmaps_whole_brain_unshimmed=[]\n",
        "sd_field_maps_whole_brain = {}\n",
        "# Iterate over each subject\n",
        "subjects_list = ['sub-1', 'sub-2', 'sub-3', 'sub-4', 'sub-5']\n",
        "for subject in subjects_list:\n",
        "    sd_field_maps_whole_brain[subject] = {}\n",
        "    derivative_path = current_path + f\"/derivatives/{subject}/\"\n",
        "    brain_mask_nii = nib.load(derivative_path + 'bet_anat_mask.nii.gz')\n",
        "\n",
        "    unshimmed_fieldmap_Grad = nib.load (derivative_path + f\"fmap/{subject}_acq-grad-fieldmap.nii.gz\").get_fdata()\n",
        "    unshimmed_fieldmap_PI = nib.load (derivative_path + f\"fmap/{subject}_acq-pi-fieldmap.nii.gz\").get_fdata()\n",
        "    unshimmed_fieldmap_LSq= nib.load (derivative_path + f\"fmap/{subject}_acq-lsq-fieldmap.nii.gz\").get_fdata()\n",
        "    unshimmed_fieldmap_QuadProg = nib.load (derivative_path + f\"fmap/{subject}_acq-quadprog-fieldmap.nii.gz\").get_fdata()\n",
        "\n",
        "    shimmed_fieldmap_Grad = nib.load (derivative_path + f\"fmap/static_shim_grad/Whole_brian_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_PI = nib.load (derivative_path + f\"fmap/static_shim_pi/Whole_brian_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_LSq= nib.load (derivative_path + f\"fmap/static_shim_lsq/Whole_brian_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_QuadProg = nib.load (derivative_path + f\"fmap/static_shim_quadprog/Whole_brian_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_Siemens = nib.load (derivative_path + f\"fmap/{subject}_acq-siemens-fieldmap.nii.gz\")\n",
        "\n",
        "    brain_mask= nilearn.image.resample_img(brain_mask_nii, target_affine=shimmed_fieldmap_Siemens.affine,target_shape=shimmed_fieldmap_Siemens.shape, interpolation='nearest').get_fdata()\n",
        "    all_Grad_fmaps_whole_brain_shimmed.append(shimmed_fieldmap_Grad[brain_mask>0].flatten())\n",
        "    all_PI_fmaps_whole_brain_shimmed.append(shimmed_fieldmap_PI[brain_mask>0].flatten())\n",
        "    all_LSq_fmaps_whole_brain_shimmed.append(shimmed_fieldmap_LSq[brain_mask>0].flatten())\n",
        "    all_QuadProg_fmaps_whole_brain_shimmed.append(shimmed_fieldmap_QuadProg[brain_mask>0].flatten())\n",
        "\n",
        "    all_Grad_fmaps_whole_brain_unshimmed.append(unshimmed_fieldmap_Grad[brain_mask>0].flatten())\n",
        "    all_PI_fmaps_whole_brain_unshimmed.append(unshimmed_fieldmap_PI[brain_mask>0].flatten())\n",
        "    all_LSq_fmaps_whole_brain_unshimmed.append(unshimmed_fieldmap_LSq[brain_mask>0].flatten())\n",
        "    all_QuadProg_fmaps_whole_brain_unshimmed.append(unshimmed_fieldmap_QuadProg[brain_mask>0].flatten())\n",
        "\n",
        "    fmaps = [unshimmed_fieldmap_PI, shimmed_fieldmap_PI, unshimmed_fieldmap_QuadProg, shimmed_fieldmap_QuadProg, unshimmed_fieldmap_LSq, shimmed_fieldmap_LSq, unshimmed_fieldmap_Grad, shimmed_fieldmap_Grad]\n",
        "    labels = [\"Unshimmed PI\", \"Shimmed PI\", \"Unshimmed QuadProg\", \"Shimmed QuadProg\", \"Unshimmed LSq\", \"Shimmed LSq\", \"Unshimmed Grad\", \"Shimmed Grad\"]\n",
        "    source_dir = os.getcwd()\n",
        "    output = derivative_path\n",
        "    sd = analyse_fieldmap(source_dir, labels, fmaps, output, brain_mask, subject, roi_name='brain',fig_size=(12,10))\n",
        "    sd_field_maps_whole_brain[subject]= sd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYUy0Fo4kuYZ"
      },
      "outputs": [],
      "source": [
        "# Calculate standard deviation for each method across all subjects\n",
        "std_dict = {}\n",
        "for key in sd_field_maps_whole_brain['sub-2'].keys():\n",
        "    values = [sd_field_maps_whole_brain[sub][key] for sub in sd_field_maps_whole_brain]\n",
        "    std_dict[key] = np.round(np.std(values),1)\n",
        "\n",
        "print(\"Standard Deviation for Each method across all subjects:\")\n",
        "for key, value in std_dict.items():\n",
        "    print(f\"{key}: {value} Hz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7848ycPZXKv"
      },
      "outputs": [],
      "source": [
        "shim_methods=[ \"PI\", \"QuadProg\", \"LSq\", \"Grad\"]\n",
        "\n",
        "for method in shim_methods:\n",
        "    # Create the variable name dynamically\n",
        "    var_name_unshimmed = f\"all_{method}_data_whole_brain_unshimmed\"\n",
        "    var_name_shimmed = f\"all_{method}_data_whole_brain_shimmed\"\n",
        "\n",
        "    # Extract the data for the current method\n",
        "    data_unshimmed = locals()[f\"all_{method}_fmaps_whole_brain_unshimmed\"]\n",
        "    data_shimmed = locals()[f\"all_{method}_fmaps_whole_brain_shimmed\"]\n",
        "\n",
        "    concat_data_unshimmed = np.concatenate(data_unshimmed)\n",
        "    concat_data_shimmed = np.concatenate(data_shimmed)\n",
        "\n",
        "    # Assign the concat_data to the dynamically created variable\n",
        "    exec(f\"{var_name_unshimmed} = concat_data_unshimmed\")\n",
        "    exec(f\"{var_name_shimmed} = concat_data_shimmed\")\n",
        "\n",
        "\n",
        "fmaps = [all_PI_data_whole_brain_unshimmed, all_PI_data_whole_brain_shimmed, all_QuadProg_data_whole_brain_unshimmed, all_QuadProg_data_whole_brain_shimmed,\n",
        "         all_LSq_data_whole_brain_unshimmed, all_LSq_data_whole_brain_shimmed, all_Grad_data_whole_brain_unshimmed, all_Grad_data_whole_brain_shimmed]\n",
        "labels = [\"Unshimmed PI\", \"Shimmed PI\", \"Unshimmed QuadProg\", \"Shimmed QuadProg\", \"Unshimmed LSq\", \"Shimmed LSq\", \"Unshimmed Grad\", \"Shimmed Grad\"]\n",
        "\n",
        "source_dir = os.getcwd()\n",
        "output = 'derivatives/All_subjects'\n",
        "subject = 'All subjects'\n",
        "distribution = analyse_fieldmap(source_dir, labels, fmaps, output, brain_mask, subject, roi_name='Brain',fig_size=(12,10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hjBluSGZXKw"
      },
      "source": [
        "#### 6.2.2 Shimming on MRS mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUpZ33DfZXKw"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_Grad_fmaps_mrs_mask_unshimmed=[]\n",
        "all_PI_fmaps_mrs_mask_unshimmed=[]\n",
        "all_LSq_fmaps_mrs_mask_unshimmed=[]\n",
        "all_QuadProg_fmaps_mrs_mask_unshimmed=[]\n",
        "\n",
        "all_Siemens_fmaps_mrs_mask_shimmed=[]\n",
        "all_Grad_fmaps_mrs_mask_shimmed=[]\n",
        "all_PI_fmaps_mrs_mask_shimmed=[]\n",
        "all_LSq_fmaps_mrs_mask_shimmed=[]\n",
        "all_QuadProg_fmaps_mrs_mask_shimmed=[]\n",
        "sd_field_maps_mrs_mask = {}\n",
        "\n",
        "# Iterate over each subject\n",
        "subjects_list = ['sub-1', 'sub-2', 'sub-3', 'sub-4', 'sub-5']\n",
        "for subject in subjects_list:\n",
        "    sd_field_maps_mrs_mask[subject] = {}\n",
        "    derivative_path = current_path + f\"/derivatives/{subject}/\"\n",
        "    mask_mrs_nii = nib.load(derivative_path + 'mask_mrs.nii.gz')\n",
        "    mask_mrs = mask_mrs_nii.get_fdata()\n",
        "\n",
        "    unshimmed_fieldmap_Grad = nib.load (derivative_path + f\"fmap/{subject}_acq-grad-fieldmap.nii.gz\").get_fdata()\n",
        "    unshimmed_fieldmap_PI = nib.load (derivative_path + f\"fmap/{subject}_acq-pi-fieldmap.nii.gz\").get_fdata()\n",
        "    unshimmed_fieldmap_LSq= nib.load (derivative_path + f\"fmap/{subject}_acq-lsq-fieldmap.nii.gz\").get_fdata()\n",
        "    unshimmed_fieldmap_QuadProg = nib.load (derivative_path + f\"fmap/{subject}_acq-quadprog-fieldmap.nii.gz\").get_fdata()\n",
        "\n",
        "    shimmed_fieldmap_Grad = nib.load (derivative_path + f\"fmap/static_shim_grad/MRS_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_PI = nib.load (derivative_path + f\"fmap/static_shim_pi/MRS_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_LSq= nib.load (derivative_path + f\"fmap/static_shim_lsq/MRS_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_QuadProg = nib.load (derivative_path + f\"fmap/static_shim_quadprog/MRS_mask/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    shimmed_fieldmap_Siemens = nib.load (derivative_path + f\"fmap/{subject}_acq-siemens-fieldmap.nii.gz\").get_fdata()\n",
        "\n",
        "    all_Grad_fmaps_mrs_mask_unshimmed.append(unshimmed_fieldmap_Grad[mask_mrs==1].flatten())\n",
        "    all_PI_fmaps_mrs_mask_unshimmed.append(unshimmed_fieldmap_PI[mask_mrs==1].flatten())\n",
        "    all_LSq_fmaps_mrs_mask_unshimmed.append(unshimmed_fieldmap_LSq[mask_mrs==1].flatten())\n",
        "    all_QuadProg_fmaps_mrs_mask_unshimmed.append(unshimmed_fieldmap_QuadProg[mask_mrs==1].flatten())\n",
        "\n",
        "    all_Siemens_fmaps_mrs_mask_shimmed.append(shimmed_fieldmap_Siemens[mask_mrs==1].flatten())\n",
        "    all_Grad_fmaps_mrs_mask_shimmed.append(shimmed_fieldmap_Grad[mask_mrs==1].flatten())\n",
        "    all_PI_fmaps_mrs_mask_shimmed.append(shimmed_fieldmap_PI[mask_mrs==1].flatten())\n",
        "    all_LSq_fmaps_mrs_mask_shimmed.append(shimmed_fieldmap_LSq[mask_mrs==1].flatten())\n",
        "    all_QuadProg_fmaps_mrs_mask_shimmed.append(shimmed_fieldmap_QuadProg[mask_mrs==1].flatten())\n",
        "\n",
        "    fmaps = [unshimmed_fieldmap_PI, shimmed_fieldmap_PI, unshimmed_fieldmap_QuadProg, shimmed_fieldmap_QuadProg, unshimmed_fieldmap_LSq, shimmed_fieldmap_LSq,\n",
        "             unshimmed_fieldmap_Grad, shimmed_fieldmap_Grad, shimmed_fieldmap_Siemens]\n",
        "    labels = [\"Unshimmed PI\", \"Shimmed PI\", \"Unshimmed QuadProg\", \"Shimmed QuadProg\", \"Unshimmed LSq\", \"Shimmed LSq\", \"Unshimmed Grad\",\n",
        "              \"Shimmed Grad\", \"Shimmed Siemens\"]\n",
        "\n",
        "    source_dir = os.getcwd()\n",
        "    output = derivative_path\n",
        "    sd = analyse_fieldmap(source_dir, labels, fmaps, output, mask_mrs, subject, roi_name='MRS', fig_size=(12,10))\n",
        "    sd_field_maps_mrs_mask[subject] =sd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1atfozwZXKw"
      },
      "outputs": [],
      "source": [
        "# Calculate standard deviation for each method across all subjects\n",
        "std_dict = {}\n",
        "for key in sd_field_maps_mrs_mask['sub-2'].keys():\n",
        "    values = [sd_field_maps_mrs_mask[sub][key] for sub in sd_field_maps_mrs_mask]\n",
        "    std_dict[key] = np.round(np.std(values),1)\n",
        "\n",
        "print(\"Standard Deviation for Each method across all subjects:\")\n",
        "for key, value in std_dict.items():\n",
        "    print(f\"{key}: {value} Hz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ-gGInpZXKw"
      },
      "outputs": [],
      "source": [
        "shim_methods=[ \"PI\", \"QuadProg\", \"LSq\", \"Grad\"]\n",
        "\n",
        "for method in shim_methods:\n",
        "    # Create the variable name dynamically\n",
        "    var_name_unshimmed = f\"all_{method}_data_mrs_mask_unshimmed\"\n",
        "    var_name_shimmed = f\"all_{method}_data_mrs_mask_shimmed\"\n",
        "    var_Siemens= f\"all_Siemens_data_mrs_mask_shimmed\"\n",
        "    # Extract the data for the current method\n",
        "    data_unshimmed = locals()[f\"all_{method}_fmaps_mrs_mask_unshimmed\"]\n",
        "    data_shimmed = locals()[f\"all_{method}_fmaps_mrs_mask_shimmed\"]\n",
        "    data_Siemens = locals()[f\"all_Siemens_fmaps_mrs_mask_shimmed\"]\n",
        "\n",
        "    concat_data_unshimmed = np.concatenate(data_unshimmed)\n",
        "    concat_data_shimmed = np.concatenate(data_shimmed)\n",
        "    concat_data_Siemens = np.concatenate(data_Siemens)\n",
        "\n",
        "    # Assign the concat_data to the dynamically created variable\n",
        "    exec(f\"{var_name_unshimmed} = concat_data_unshimmed\")\n",
        "    exec(f\"{var_name_shimmed} = concat_data_shimmed\")\n",
        "    exec(f\"{var_Siemens} = concat_data_Siemens\")\n",
        "\n",
        "fmaps = [all_PI_data_mrs_mask_unshimmed, all_PI_data_mrs_mask_shimmed, all_QuadProg_data_mrs_mask_unshimmed, all_QuadProg_data_mrs_mask_shimmed,\n",
        "         all_LSq_data_mrs_mask_unshimmed, all_LSq_data_mrs_mask_shimmed, all_Grad_data_mrs_mask_unshimmed, all_Grad_data_mrs_mask_shimmed, all_Siemens_data_mrs_mask_shimmed]\n",
        "labels = [\"Unshimmed PI\", \"Shimmed PI\", \"Unshimmed QuadProg\", \"Shimmed QuadProg\", \"Unshimmed LSq\", \"Shimmed LSq\", \"Unshimmed Grad\", \"Shimmed Grad\", \"Shimmed Siemens\"]\n",
        "\n",
        "source_dir = os.getcwd()\n",
        "output = 'derivatives/All_subjects'\n",
        "subject = 'All subjects'\n",
        "distribution = analyse_fieldmap(source_dir, labels, fmaps, output, mask_mrs, subject, roi_name='MRS',fig_size=(12,10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxV_fOYkuYZ"
      },
      "source": [
        "### 6.3 Perform statistical test on fieldmaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHG45IZckuYa"
      },
      "source": [
        "By comparing the variance, the following cell assesses whether the distribution of each shimming method significantly differs from the Siemens shimming.\n",
        "The documentation for the following tests can be found [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html#scipy.stats.kstest) and [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4yjBeiDZXKx"
      },
      "source": [
        "### 6.3.1 On whole brain data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqqyK-LVkuYa"
      },
      "outputs": [],
      "source": [
        "import statsmodels.stats.multitest as smm\n",
        "# Kolmogorov-Smirnov test to check the normality of the reference distribution (Siemens shimming)\n",
        "statistic, p_value_normality = stats.kstest(all_PI_data_whole_brain_shimmed, 'norm')\n",
        "\n",
        "# Set significant level\n",
        "alpha = 0.01\n",
        "\n",
        "# Interpret the results\n",
        "# H0: the sample has a Gaussian distribution.\n",
        "# H1: the sample does not have a Gaussian distribution.\n",
        "if p_value_normality < alpha:\n",
        "    print('Reject the null hypothesis. The provided data does not follow a normal distribution.')\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The provided data follow a normal distribution.\")\n",
        "\n",
        "comparison_methods= ['Grad', 'LSq', 'QuadProg']\n",
        "Uncor_pvals = []\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data_whole_brain_shimmed\")\n",
        "    statistic, p_value = stats.levene(all_PI_data_whole_brain_shimmed, data)\n",
        "    Uncor_pvals.append(p_value)\n",
        "print(\"Uncorrected p-values are: \", Uncor_pvals)\n",
        "\n",
        "# Perform Multiple comparison correction with step-down method using Bonferroni adjustments\n",
        "Corrected_pvals = smm.multipletests(Uncor_pvals, alpha=0.01, method='holm', is_sorted=False, returnsorted=False)\n",
        "print(\"Corrected p-values are: \" , Corrected_pvals[1])\n",
        "\n",
        "for pval, method in zip(Corrected_pvals[1], comparison_methods):\n",
        "  if pval < 0.01:\n",
        "    print(f\"Reject the null hypothesis. The variance between the PI and {method} groups are significantly different.\")\n",
        "  else:\n",
        "    print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the PI and {method} groups.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIJzw0oZkuYa"
      },
      "outputs": [],
      "source": [
        "# Comparing Grad method to other methods\n",
        "\n",
        "comparison_methods= ['PI', 'QuadProg', 'LSq']\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data_whole_brain_shimmed\")\n",
        "    statistic, p_value = stats.levene(all_Grad_data_whole_brain_shimmed, data)\n",
        "\n",
        "    # Set significancy level\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Interpret the results\n",
        "    if p_value < alpha:\n",
        "        print(f\"Reject the null hypothesis. The variance between the Grad and {method} groups are significantly different.\")\n",
        "    else:\n",
        "        print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the Grad and {method} groups.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoncgGQzkuYa"
      },
      "outputs": [],
      "source": [
        "# Comparing PI method to others\n",
        "\n",
        "comparison_methods= ['Grad', 'QuadProg', 'LSq']\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data_whole_brain_shimmed\")\n",
        "    statistic, p_value = stats.levene(all_PI_data_whole_brain_shimmed, data)\n",
        "\n",
        "    # Set significancy level\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Interpret the results\n",
        "    if p_value < alpha:\n",
        "        print(f\"Reject the null hypothesis. The variance between the PI and {method} groups are significantly different.\")\n",
        "    else:\n",
        "        print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the PI and {method} groups.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZD50fHsZXK1"
      },
      "source": [
        "### On MRS mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEeGCp55ZXK1"
      },
      "outputs": [],
      "source": [
        "import statsmodels.stats.multitest as smm\n",
        "# Kolmogorov-Smirnov test to check the normality of the reference distribution (Siemens shimming)\n",
        "statistic, p_value_normality = stats.kstest(all_Siemens_data_mrs_mask_shimmed, 'norm')\n",
        "\n",
        "# Set significant level\n",
        "alpha = 0.01\n",
        "\n",
        "# Interpret the results\n",
        "# H0: the sample has a Gaussian distribution.\n",
        "# H1: the sample does not have a Gaussian distribution.\n",
        "if p_value_normality < alpha:\n",
        "    print('Reject the null hypothesis. The provided data does not follow a normal distribution.')\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The provided data follow a normal distribution.\")\n",
        "\n",
        "comparison_methods= ['PI','Grad', 'LSq', 'QuadProg']\n",
        "Uncor_pvals = []\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data_mrs_mask_shimmed\")\n",
        "    statistic, p_value = stats.levene(all_Siemens_data_mrs_mask_shimmed, data)\n",
        "    Uncor_pvals.append(p_value)\n",
        "print(\"Uncorrected p-values are: \", Uncor_pvals)\n",
        "\n",
        "# Perform Multiple comparison correction with step-down method using Bonferroni adjustments\n",
        "Corrected_pvals = smm.multipletests(Uncor_pvals, alpha=0.01, method='holm', is_sorted=False, returnsorted=False)\n",
        "print(\"Corrected p-values are: \" , Corrected_pvals[1])\n",
        "\n",
        "for pval, method in zip(Corrected_pvals[1], comparison_methods):\n",
        "  if pval < 0.01:\n",
        "    print(f\"Reject the null hypothesis. The variance between the Siemens and {method} groups are significantly different.\")\n",
        "  else:\n",
        "    print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the Siemens and {method} groups.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LXgQCZDZXK2"
      },
      "outputs": [],
      "source": [
        "# Comparing Grad method to other methods\n",
        "\n",
        "comparison_methods= ['PI', 'QuadProg', 'LSq']\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data_mrs_mask_shimmed\")\n",
        "    statistic, p_value = stats.levene(all_Grad_data_mrs_mask_shimmed, data)\n",
        "\n",
        "    # Set significancy level\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Interpret the results\n",
        "    if p_value < alpha:\n",
        "        print(f\"Reject the null hypothesis. The variance between the Grad and {method} groups are significantly different.\")\n",
        "    else:\n",
        "        print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the Grad and {method} groups.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgixo125ZXK2"
      },
      "outputs": [],
      "source": [
        "# Comparing PI method to other methods\n",
        "\n",
        "comparison_methods= ['Grad', 'QuadProg', 'LSq']\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data_mrs_mask_shimmed\")\n",
        "    statistic, p_value = stats.levene(all_PI_data_mrs_mask_shimmed, data)\n",
        "\n",
        "    # Set significancy level\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Interpret the results\n",
        "    if p_value < alpha:\n",
        "        print(f\"Reject the null hypothesis. The variance between the PI and {method} groups are significantly different.\")\n",
        "    else:\n",
        "        print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the PI and {method} groups.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyoZVUyblTJD"
      },
      "source": [
        "## 7. MRS analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edgU0UwLkuYa"
      },
      "source": [
        "###  5.1. Water removal and fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEz2anTYkuYb"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "subjects_list=$(find .  -type d -maxdepth 1 -name \"sub-*\")\n",
        "IFS=$'\\n' read -d '' -r -a subjects_array <<< \"$subjects_list\"\n",
        "echo \"subjects list are: $subjects_list\"\n",
        "\n",
        "path_derivatives=$(find . -type d -name derivatives)\n",
        "echo \"derivatives path is: ${path_derivatives}\"\n",
        "\n",
        "for subject in \"${subjects_array[@]}\"; do\n",
        "    echo \"Analyzing subject: ${subject}\"\n",
        "    path_mrs=$(find ${subject} -type d -name mrs)\n",
        "    echo \"mrs path is: ${path_mrs}\"\n",
        "    path_t1=$(find ${subject} -type f -name *T1w.nii.gz)\n",
        "    echo \"T1 path is: ${path_t1}\"\n",
        "    sub_basename=$(basename \"${subject}\")\n",
        "    subject_derivatives=${path_derivatives}/${sub_basename}/mrs\n",
        "    echo \"${sub_basename} derivatives path is: ${subject_derivatives}\"\n",
        "\n",
        "    shim_methods=(\"siemens\" \"pi\" \"quadprog\" \"lsq\" \"grad\")\n",
        "    for method in \"${shim_methods[@]}\"; do\n",
        "        fsl_mrs_proc remove --file ${path_mrs}/${subject}_acq-press-${method}-shim_nuc-H_echo-135_svs.nii.gz --output ${subject_derivatives}/${method}_water_removed -r  --ppm 3.5 9\n",
        "        fsl_mrs  --data ${subject_derivatives}/${method}_water_removed/${subject}_acq-press-${method}-shim_nuc-H_echo-135_svs.nii.gz --basis ${path_derivatives}/LCModel_Siemens_UnEdited_PRESS_135_ALL.BASIS --t1 ${path_t1} --output ${subject_derivatives}/${method}_fit_result --baseline_order 2   --internal_ref 'Cr' --ignore H2O PCr GPC  --report --overwrite --ppmlim 0 4 --TE 135 --TR 2\n",
        "    done\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF0j-YDBkuYb"
      },
      "source": [
        "### 7.2 Plot the fittings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_da0nkJkuYb"
      },
      "outputs": [],
      "source": [
        "# Iterate over each subject\n",
        "current_path = os.getcwd()\n",
        "index = 1\n",
        "plt.figure(figsize=(40, 40))\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "shim_methods=['siemens','pi' ,'quadprog' ,'lsq','grad']\n",
        "for subject in subjects_list:\n",
        "    for method in shim_methods:\n",
        "        fit_path = current_path + f\"/derivatives/{subject}/mrs/{method}_fit_result/\"\n",
        "        plt.subplot(len(subjects_list),len(shim_methods), index)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(plt.imread(fit_path + 'fit_summary.png'))\n",
        "        plt.title(f\" {subject}_{method}_shim\", fontsize=14)\n",
        "        index += 1\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.savefig(current_path + '/derivatives/All_subjects/mrs_fittings.png', dpi=300, bbox_inches='tight')\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOsM9FkgkuYb"
      },
      "source": [
        "### 7.3. Extract the metabolites fit results from the CSV files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rbgG8qEXkuYb"
      },
      "outputs": [],
      "source": [
        "# Example path to the current directory\n",
        "current_path = os.getcwd()\n",
        "\n",
        "# Iterate over each subject and shim method to extract CRLB values\n",
        "crlb_NAA_all = {}\n",
        "crlb_CR_all = {}\n",
        "crlb_CHO_all = {}\n",
        "fwhm_NAA_all = {}\n",
        "snr_NAA_all = {}\n",
        "fwhm_CR_all = {}\n",
        "snr_CR_all = {}\n",
        "fwhm_CHO_all = {}\n",
        "snr_CHO_all = {}\n",
        "\n",
        "index = 1\n",
        "for subject in subjects_list:\n",
        "    crlb_NAA_all[subject] = {}\n",
        "    crlb_CR_all[subject] = {}\n",
        "    crlb_CHO_all[subject] = {}\n",
        "    fwhm_NAA_all[subject] = {}\n",
        "    snr_NAA_all[subject] = {}\n",
        "    fwhm_CR_all[subject] = {}\n",
        "    snr_CR_all[subject] = {}\n",
        "    fwhm_CHO_all[subject] = {}\n",
        "    snr_CHO_all[subject] = {}\n",
        "    for method in shim_methods:\n",
        "        fit_path = os.path.join(current_path, f\"derivatives/{subject}/mrs/{method}_fit_result/\")\n",
        "\n",
        "        # Read summary.csv file\n",
        "        summary_file_path = os.path.join(fit_path, 'summary.csv')\n",
        "        if os.path.exists(summary_file_path):\n",
        "            df = pd.read_csv(summary_file_path)\n",
        "            # if method == 'quadprog':\n",
        "            #     print(df)\n",
        "            #     print(df.at[2, '%CRLB'])\n",
        "\n",
        "            # Get the values for NAA, cr, cho\n",
        "            CRLB_Cr = df.at[2, '%CRLB']\n",
        "            crlb_CR_all[subject][method] = CRLB_Cr\n",
        "\n",
        "            CRLB_CHO = df.at[13, '%CRLB']\n",
        "            crlb_CHO_all[subject][method] = CRLB_CHO\n",
        "\n",
        "            CRLB_NAA = df.at[11, '%CRLB']\n",
        "            crlb_NAA_all[subject][method] = CRLB_NAA\n",
        "\n",
        "            fwhm_NAA = df.at[11, 'FWHM']\n",
        "            snr_NAA = df.at[11, 'SNR']\n",
        "            fwhm_NAA_all[subject][method] = fwhm_NAA\n",
        "            snr_NAA_all[subject][method] = snr_NAA\n",
        "\n",
        "            fwhm_CR = df.at[2, 'FWHM']\n",
        "            snr_CR = df.at[2, 'SNR']\n",
        "            fwhm_CR_all[subject][method] = fwhm_CR\n",
        "            snr_CR_all[subject][method] = snr_CR\n",
        "\n",
        "            fwhm_CHO = df.at[13, 'FWHM']\n",
        "            snr_CHO = df.at[13, 'SNR']\n",
        "            fwhm_CHO_all[subject][method] = fwhm_CHO\n",
        "            snr_CHO_all[subject][method] = snr_CHO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVF25dC0lTJF"
      },
      "source": [
        "### 7.4. Comparing metabolites' FWHM and SNR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewauhiqUkuYc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "metab_list= ['NAA', 'CR', 'CHO']\n",
        "# Create figure and axes\n",
        "fig, axs = plt.subplots(len(metab_list), 3, figsize=(18, 18))\n",
        "import matplotlib.markers as mmarkers\n",
        "\n",
        "# Define a horizontal line marker\n",
        "hline_marker = mmarkers.MarkerStyle('_')\n",
        "hline_marker._transform = hline_marker.get_transform().scale(5, 5)\n",
        "mean_fwhm_all = {}\n",
        "mean_snr_all = {}\n",
        "mean_crlb_all = {}\n",
        "for i, metab in enumerate(metab_list):\n",
        "    # Compute the mean values for FWHM and SNR for each metabolite\n",
        "    mean_fwhm = {key: np.round(np.mean([globals()[f'fwhm_{metab}_all'][sub][key] for sub in globals()[f'fwhm_{metab}_all']]), decimals=1) for key in globals()[f'fwhm_{metab}_all']['sub-1'].keys()}\n",
        "    mean_snr = {key: np.round(np.mean([globals()[f'snr_{metab}_all'][sub][key] for sub in globals()[f'snr_{metab}_all']]), decimals=1) for key in globals()[f'snr_{metab}_all']['sub-1'].keys()}\n",
        "    mean_crlb = {key: np.round(np.mean([globals()[f'crlb_{metab}_all'][sub][key] for sub in globals()[f'crlb_{metab}_all']]), decimals=1) for key in globals()[f'crlb_{metab}_all']['sub-1'].keys()}\n",
        "    mean_fwhm_all[metab] = mean_fwhm\n",
        "    mean_snr_all[metab] = mean_snr\n",
        "    mean_crlb_all[metab] = mean_crlb\n",
        "\n",
        "    # Plot FWHM\n",
        "    axs[i, 0].set_title(f\"FWHM (Hz) {metab}\", fontsize=18)\n",
        "    for sub in globals()[f'fwhm_{metab}_all']:\n",
        "        axs[i, 0].scatter(list(globals()[f'fwhm_{metab}_all'][sub].keys()), list(globals()[f'fwhm_{metab}_all'][sub].values()), label=sub)\n",
        "    axs[i, 0].scatter(list(mean_fwhm.keys()), list(mean_fwhm.values()), color='black', marker=hline_marker, label='mean')\n",
        "    axs[i, 0].legend(prop={'size': 15}, loc='upper right', bbox_to_anchor=(0.4, 1))\n",
        "    axs[i, 0].tick_params(axis='x', rotation=45, labelsize=14)\n",
        "    axs[i, 0].yaxis.set_minor_locator(plt.MultipleLocator(1))  # Set minor ticks for y-axis\n",
        "    axs[i, 0].grid(which='major', axis='x')\n",
        "\n",
        "    # Plot SNR\n",
        "    axs[i, 1].set_title(f\"SNR (A.U.) {metab}\", fontsize=18)\n",
        "    for sub in globals()[f'snr_{metab}_all']:\n",
        "        axs[i, 1].scatter(list(globals()[f'snr_{metab}_all'][sub].keys()), list(globals()[f'snr_{metab}_all'][sub].values()), label=sub)\n",
        "    axs[i, 1].scatter(list(mean_snr.keys()), list(mean_snr.values()), color='black', marker= hline_marker, label='mean')\n",
        "    axs[i, 1].legend(prop={'size': 15}, loc='upper right', bbox_to_anchor=(0.9, 1))\n",
        "    axs[i, 1].tick_params(axis='x', rotation=45, labelsize=14)\n",
        "    axs[i, 1].yaxis.set_minor_locator(plt.MultipleLocator(1))  # Set minor ticks for y-axis\n",
        "    axs[i, 1].grid(which='major', axis='x')\n",
        "\n",
        "\n",
        "    # Plot crlb\n",
        "    axs[i, 2].set_title(f\"CRLB (%) {metab}\", fontsize=18)\n",
        "    for sub in globals()[f'crlb_{metab}_all']:\n",
        "        axs[i, 2].scatter(list(globals()[f'crlb_{metab}_all'][sub].keys()), list(globals()[f'crlb_{metab}_all'][sub].values()), label=sub)\n",
        "    axs[i, 2].scatter(list(mean_crlb.keys()), list(mean_crlb.values()), color='black', marker= hline_marker, label='mean')\n",
        "    axs[i, 2].legend(prop={'size': 15}, loc='upper right', bbox_to_anchor=(0.5, 1))\n",
        "    axs[i, 2].tick_params(axis='x', rotation=45, labelsize=14)\n",
        "    axs[i, 2].yaxis.set_minor_locator(plt.MultipleLocator(1))  # Set minor ticks for y-axis\n",
        "    axs[i, 2].grid(which='major', axis='x')\n",
        "\n",
        "     # Set x tick labels\n",
        "    axs[i, 0].set_xticklabels([\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"])\n",
        "    axs[i, 1].set_xticklabels([\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"])\n",
        "    axs[i, 2].set_xticklabels([\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"])\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "plt.savefig(current_path + '/derivatives/All_subjects/FWHM_SNR_comparison.png', dpi=300, bbox_inches='tight')\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG21mJzQkuYc"
      },
      "source": [
        "### 7.5. Create a CSV output  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVBs4Dz5kuYc"
      },
      "outputs": [],
      "source": [
        "# Initialize lists for each criteria\n",
        "all_data_dicts_fwhm = []\n",
        "all_data_dicts_snr = []\n",
        "all_data_dicts_crlb = []\n",
        "current_path = os.getcwd()\n",
        "criteria_list = ['fwhm', 'snr', 'crlb']\n",
        "\n",
        "for criteria in criteria_list:\n",
        "    mean_criteria_all = globals()[f'mean_{criteria}_all']\n",
        "\n",
        "    # Calculate the percentage difference for each dictionary\n",
        "    percentage_diff_dict = {}\n",
        "    for metab, values in mean_criteria_all.items():\n",
        "        siemens_value = values['siemens']\n",
        "        percentage_diff = {}\n",
        "        for key, value in values.items():\n",
        "            if key != 'siemens':\n",
        "                percentage_diff[key] = ((value - siemens_value) / siemens_value) * 100\n",
        "        percentage_diff_dict[metab] = percentage_diff\n",
        "\n",
        "    # Concatenate the original data and the percentage difference data\n",
        "    for metab, values in mean_criteria_all.items():\n",
        "        combined_dict = {'metabolite': metab}\n",
        "        for key, value in values.items():\n",
        "            combined_dict[f'{key}'] = round(value, 1)  # Round to one decimal place\n",
        "            if key != 'siemens':\n",
        "                combined_dict[f'{key} change (%)'] = round(percentage_diff_dict[metab].get(key, None), 1)  # Round to one decimal place\n",
        "        if criteria == 'fwhm':\n",
        "            all_data_dicts_fwhm.append(combined_dict)\n",
        "        elif criteria == 'snr':\n",
        "            all_data_dicts_snr.append(combined_dict)\n",
        "        elif criteria == 'crlb':\n",
        "            all_data_dicts_crlb.append(combined_dict)\n",
        "\n",
        "# Create DataFrames for each criteria\n",
        "df_fwhm = pd.DataFrame(all_data_dicts_fwhm)\n",
        "df_snr = pd.DataFrame(all_data_dicts_snr)\n",
        "df_crlb = pd.DataFrame(all_data_dicts_crlb)\n",
        "# Display the DataFrames\n",
        "df_fwhm_styled = df_fwhm.style.set_table_styles([{'selector': 'th', 'props': [('background', '#f7f7f9'), ('color', 'black'), ('border', '1px solid #dee2e6')]}])\n",
        "df_fwhm_formatted = df_fwhm.apply(lambda x: x.apply(lambda y: '{:.1f}'.format(y) if isinstance(y, float) else y))\n",
        "\n",
        "df_snr_styled = df_snr.style.set_table_styles([{'selector': 'th', 'props': [('background', '#f7f7f9'), ('color', 'black'), ('border', '1px solid #dee2e6')]}])\n",
        "df_snr_formatted = df_snr.apply(lambda x: x.apply(lambda y: '{:.1f}'.format(y) if isinstance(y, float) else y))\n",
        "\n",
        "df_crlb_styled = df_crlb.style.set_table_styles([{'selector': 'th', 'props': [('background', '#f7f7f9'), ('color', 'black'), ('border', '1px solid #dee2e6')]}])\n",
        "df_crlb_formatted = df_crlb.apply(lambda x: x.apply(lambda y: '{:.1f}'.format(y) if isinstance(y, float) else y))\n",
        "\n",
        "# Display the styled DataFrames\n",
        "print(\"FWHM DataFrame:\")\n",
        "display(df_fwhm_formatted)\n",
        "\n",
        "print(\"SNR DataFrame:\")\n",
        "display(df_snr_formatted)\n",
        "\n",
        "print(\"CRLB DataFrame:\")\n",
        "display(df_crlb_formatted)\n",
        "\n",
        "separator_row_snr = pd.DataFrame({'metabolite': ['SNR']})\n",
        "separator_row_crlb = pd.DataFrame({'metabolite': ['CRLB']})\n",
        "# Create a separator row with repeated column names\n",
        "separator_row_columns = pd.DataFrame([df_fwhm_formatted.columns], columns=df_fwhm_formatted.columns)\n",
        "\n",
        "# Concatenate the DataFrames with the separator rows\n",
        "combined_df = pd.concat([ df_fwhm_formatted, separator_row_snr, separator_row_columns, df_snr_formatted, separator_row_crlb, separator_row_columns,df_crlb_formatted], axis=0)\n",
        "\n",
        "# Save the combined DataFrame to a CSV file\n",
        "combined_df.to_csv(current_path + '/derivatives/All_subjects/Metabolites_fit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Phs6gCJ1lTI_",
        "NEuAWZjBlTJB"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}