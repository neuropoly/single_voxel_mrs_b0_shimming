{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuropoly/single_voxel_mrs_b0_shimming/blob/main/SVS_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hjCE6GLlTI7"
      },
      "source": [
        "# SVS processing - interactive notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnaT-VdNlTI-"
      },
      "source": [
        "This notebook demos the process of fitting a single voxel MRS data using FSL-MRS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfU21cYmlTI_"
      },
      "source": [
        "## Contents:\n",
        "\n",
        "1. [Install dependencies](#1.-Install-dependencies)\n",
        "2. [Import required libraries](#2.-Import-required-libraries)\n",
        "3. [Download the data](#3.-Download-the-data)\n",
        "4. [B0 Fieldmaps calculation](#4.-Compute-fieldmaps)\n",
        "5. [B0 shimming](#5.-Perform-B0-shimming-using-the-computed-filedmaps)\n",
        "6. [B0 Fieldmaps comparison](#6.-B0-Fieldmaps-comparison)\n",
        "7. [MRS analysis](#7.-MRS-analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phs6gCJ1lTI_",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 1. Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gy_EGEgylTI_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "!git clone --recurse-submodules https://git.fmrib.ox.ac.uk/fsl/fsl_mrs.git\n",
        "%cd /content/fsl_mrs\n",
        "!pip install .\n",
        "\n",
        "%cd /content\n",
        "!git clone --single-branch --branch gradient_optimizer https://github.com/shimming-toolbox/shimming-toolbox.git\n",
        "%cd /content/shimming-toolbox/\n",
        "!pip install .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VxegHqgzUTm"
      },
      "outputs": [],
      "source": [
        "# Restart the runtime to resolve the compatibilty issues between the packages\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0IDwpEwlTJA",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 2. Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LzNltv9jwoXz"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "import os\n",
        "os.environ[\"LD_PRELOAD\"] = \"\";\n",
        "os.environ[\"APPTAINER_BINDPATH\"] = \"/content\"\n",
        "os.environ[\"MPLCONFIGDIR\"] = \"/content/matplotlib-mpldir\"\n",
        "os.environ[\"LMOD_CMD\"] = \"/usr/share/lmod/lmod/libexec/lmod\"\n",
        "os.environ[\"MODULEPATH\"] = \"/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/molecular_biology:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/workflows:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/visualization:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/structural_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/statistics:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/spine:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/spectroscopy:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/shape_analysis:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/segmentation:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/rodent_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/quantitative_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/quality_control:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/programming:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/phase_processing:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/machine_learning:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/image_segmentation:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/image_registration:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/image_reconstruction:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/hippocampus:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/functional_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/electrophysiology:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/diffusion_imaging:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/data_organisation:/cvmfs/neurodesk.ardc.edu.au/neurodesk-modules/body\"\n",
        "\n",
        "!curl -J -O https://raw.githubusercontent.com/NeuroDesk/neurocommand/main/googlecolab_setup.sh\n",
        "!chmod +x googlecolab_setup.sh\n",
        "!./googlecolab_setup.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fArgkjVwnurU"
      },
      "outputs": [],
      "source": [
        "import lmod\n",
        "await lmod.load('fsl/6.0.4')\n",
        "await lmod.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q08UP-P5lTJB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import datetime\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from IPython.display import HTML\n",
        "import fsl_mrs.utils.mrs_io as mrs_io\n",
        "from fsl_mrs.utils.preproc import nifti_mrs_proc as proc\n",
        "import fsl_mrs as mrs\n",
        "from fsl_mrs.utils import report, fitting, misc, plotting\n",
        "from shimmingtoolbox.prepare_fieldmap import prepare_fieldmap\n",
        "from shimmingtoolbox.load_nifti import read_nii\n",
        "from shimmingtoolbox.cli import b0shim\n",
        "from shimmingtoolbox.masking.threshold import threshold as mask_threshold\n",
        "\n",
        "try:\n",
        "    import nilearn\n",
        "    import seaborn as sns\n",
        "    import plotly.graph_objects as go\n",
        "    import plotly.io as pio\n",
        "\n",
        "except ImportError:\n",
        "    !pip install seaborn\n",
        "    import seaborn as sns\n",
        "    !pip install nilearn\n",
        "    import nilearn\n",
        "    !pip install plotly\n",
        "    import plotly.graph_objects as go\n",
        "    import plotly.io as pio\n",
        "\n",
        "!pip install osfclient\n",
        "\n",
        "print('Necessary libraries are imported')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEuAWZjBlTJB",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 3. Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWe7aUwCt4G3"
      },
      "outputs": [],
      "source": [
        "!osf -p s3gwv fetch /SVS_MRS_DATA.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2VUS0SmWlTJC"
      },
      "outputs": [],
      "source": [
        "# Unzip the data\n",
        "zipped_data = \"/content/\" + \"SVS_MRS_DATA.zip\"\n",
        "with zipfile.ZipFile(zipped_data,\"r\") as zipfile:\n",
        "  zipfile.extractall('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ovVOFv1ve2J"
      },
      "source": [
        "## 4. Compute fieldmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2U5h7uEJlTJD"
      },
      "outputs": [],
      "source": [
        "if os.path.basename(os.getcwd()) != 'SVS_MRS_DATA':\n",
        "    os.chdir(os.getcwd()+'/SVS_MRS_DATA/')\n",
        "\n",
        "current_path = os.getcwd()\n",
        "print(\"current path is: \", current_path)\n",
        "shim_methods=['siemens','pi' ,'quadprog' ,'lsq','grad']\n",
        "subjects_list = [name for name in os.listdir() if os.path.isdir(name) and name.startswith('sub')]\n",
        "subjects_list.sort(key=lambda x: int(x.split('-')[1]))\n",
        "print(\"subjects list are: \", subjects_list)\n",
        "\n",
        "# Iterate over each subject\n",
        "for subject in subjects_list:\n",
        "    derivative_path = current_path + f\"/derivatives/{subject}/\"\n",
        "    fmap_path = f\"{derivative_path}fmap/\"\n",
        "    if not os.path.exists(fmap_path):\n",
        "        os.makedirs(fmap_path)\n",
        "\n",
        "    mask_mrs_nii = nib.load(derivative_path + 'mask_mrs.nii.gz')\n",
        "    mask_mrs = mask_mrs_nii.get_fdata()\n",
        "    mask_anat_nii = nib.load (derivative_path + 'bet_anat_mask.nii.gz')\n",
        "\n",
        "    # Iterate over each shim method\n",
        "    for method in shim_methods:\n",
        "\n",
        "        # Load the file corresponding to the method\n",
        "        gre_path =  current_path + f\"/{subject}/fmap/\"\n",
        "        mag = read_nii(gre_path + f\"{subject}_acq-{method}Shim_magnitude1.nii.gz\")\n",
        "        phase1 = read_nii(gre_path + f\"{subject}_acq-{method}Shim_phase1.nii.gz\", auto_scale=True)\n",
        "        phase2 = read_nii(gre_path + f\"{subject}_acq-{method}Shim_phase2.nii.gz\", auto_scale=True)\n",
        "\n",
        "        # Load JSON data from the magnitude nifti\n",
        "        with open(gre_path + f\"{subject}_acq-{method}Shim_magnitude1.json\", 'r') as mag_json:\n",
        "            json_data = json.load(mag_json)\n",
        "\n",
        "        phase_list_data = [phase1[2], phase2[2]]\n",
        "\n",
        "        # scale the phase data to (-pi, pi) range\n",
        "        scaled_phase_list_data = [((phase_list_data[i] - np.min(phase_list_data[i]))/(np.max(phase_list_data[i])-np.min(phase_list_data[i])))\n",
        "                             *2*np.pi-np.pi for i in range(len(phase_list_data))]\n",
        "        # convert to nifti\n",
        "        scaled_phase_list_nii = [nib.Nifti1Image(scaled_phase_list_data[i], phase1[0].affine, phase1[0].header)\n",
        "                             for i in range(len(scaled_phase_list_data))]\n",
        "\n",
        "        EchoTime1 = phase1[1]['EchoTime']\n",
        "        EchoTime2 = phase2[1]['EchoTime']\n",
        "        echo_times = [EchoTime1, EchoTime2]\n",
        "\n",
        "        # compute fieldmap for each method\n",
        "        fieldmap = prepare_fieldmap(scaled_phase_list_nii, echo_times, mag[2], unwrapper='prelude', gaussian_filter= True, nii_mask= mask_anat_nii, sigma=0.5)\n",
        "        # store the fieldmap under the corresponding path\n",
        "        fieldmap_nii = nib.Nifti1Image(fieldmap[0], phase1[0].affine, phase1[0].header )\n",
        "        nib.save(fieldmap_nii, fmap_path + f\"{subject}_acq-{method}-fieldmap.nii.gz\")\n",
        "\n",
        "        # store the corresponding json file for each fieldmap\n",
        "        with open(fmap_path + f\"{subject}_acq-{method}-fieldmap.json\", 'w') as fmap_json:\n",
        "            json.dump(json_data, fmap_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05mYNcU1XKbZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "# Create a figure with a specific size and white background\n",
        "fig = plt.figure(figsize=(12, 5), facecolor='white')\n",
        "plt.suptitle('Grad fieldmap (Hz)', fontsize=16, fontweight='bold')\n",
        "# Define gridspec\n",
        "gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 0.8])\n",
        "\n",
        "# Plot sagittal cut\n",
        "ax1 = plt.subplot(gs[0])\n",
        "ax1.imshow(np.rot90(fieldmap[0][30,:,:]), vmin=-100, vmax=100, cmap='jet')\n",
        "ax1.set_xticks([])  # Turn off x-axis ticks\n",
        "ax1.set_yticks([])  # Turn off y-axis ticks\n",
        "ax1.set_title('Sagittal', fontsize=12)\n",
        "\n",
        "# Plot coronal cut\n",
        "ax2 = plt.subplot(gs[1])\n",
        "ax2.imshow(np.rot90(fieldmap[0][:,34,:]), vmin=-100, vmax=100,  cmap='jet')\n",
        "ax2.set_xticks([])  # Turn off x-axis ticks\n",
        "ax2.set_yticks([])  # Turn off y-axis ticks\n",
        "ax2.set_title('Coronal', fontsize=12)\n",
        "\n",
        "# Plot axial cut\n",
        "ax3 = plt.subplot(gs[2])\n",
        "img = ax3.imshow(np.rot90(fieldmap[0][...,6]), vmin=-100, vmax=100,  cmap='jet')\n",
        "ax3.set_xticks([])  # Turn off x-axis ticks\n",
        "ax3.set_yticks([])  # Turn off y-axis ticks\n",
        "ax3.set_title('Axial', fontsize=12)\n",
        "cbar = plt.colorbar(img, ax=ax3)  # Add color bar\n",
        "cbar.ax.tick_params(labelsize=20)  # Set font size for color bar\n",
        "\n",
        "# Save the figure with 300 dpi\n",
        "plt.savefig('fieldmap_example.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyXMxQD_kuYY"
      },
      "source": [
        "## 5. Perform B0 shimming using the computed filedmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNQZjXnTkuYY"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Generate subjects list as an array\n",
        "subjects_list=$(find .  -type d -maxdepth 1 -name \"sub-*\"| sort -V)\n",
        "IFS=$'\\n' read -d '' -r -a subjects_array <<< \"$subjects_list\"\n",
        "echo \"subjects list are: $subjects_list\"\n",
        "\n",
        "path_derivatives=$(find . -type d -name derivatives)\n",
        "shim_methods=(\"pi\" \"quadprog\" \"lsq\" \"grad\")\n",
        "for subject in \"${subjects_array[@]}\"; do\n",
        "    echo \"Analysing Subject: $subject\"\n",
        "    subject_name=$(basename \"$subject\")\n",
        "    fmap_path=${path_derivatives}/${subject_name}\n",
        "    mask=$(find ${fmap_path} -type f -name \"mask_mrs.nii.gz\")\n",
        "    output_grad=\"${fmap_path}/fmap/static_shim_grad\"\n",
        "    output_lsq=\"${fmap_path}/fmap/static_shim_lsq\"\n",
        "    output_pi=\"${fmap_path}/fmap/static_shim_pi\"\n",
        "    output_quadprog=\"${fmap_path}/fmap/static_shim_quadprog\"\n",
        "\n",
        "    for method in \"${shim_methods[@]}\"; do\n",
        "\n",
        "        fieldmap=$(find ${path_derivatives}/${subject_name}/fmap -type f -name \"${subject_name}_acq-${method}-fieldmap.nii.gz\")\n",
        "        if [ \"${method}\" = \"lsq\" ]; then\n",
        "            st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-criteria \"mse\" --optimizer-method \"least_squares\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_lsq}\"  || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"grad\" ]; then\n",
        "            st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-criteria \"ps_huber\" --optimizer-method \"gradient\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_grad}\" || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"pi\" ]; then\n",
        "            st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-method \"pseudo_inverse\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_pi}\"  || exit\n",
        "\n",
        "        elif [ \"${method}\" = \"quadprog\" ]; then\n",
        "            st_b0shim dynamic --fmap \"${fieldmap}\" --anat \"${fieldmap}\" --mask \"${mask}\" --mask-dilation-kernel-size \"5\" --optimizer-method \"quad_prog\" --slices \"volume\" --output-file-format-scanner \"chronological-coil\" --scanner-coil-order \"0,1,2\" --output-value-format \"absolute\" --output \"${output_quadprog}\"  || exit\n",
        "\n",
        "        fi\n",
        "    done\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0qCBPnAlTJD"
      },
      "source": [
        "## 6. B0 Fieldmaps comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoEPEgcgkuYY"
      },
      "source": [
        "### 6.1 Function to analyze the fieldmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "VMkUSY6K0T7j"
      },
      "outputs": [],
      "source": [
        "def analyse_fieldmap(source_dir, labels, fieldmaps, output, mask, subject):\n",
        "    \"\"\"\n",
        "    Description: Generates a violin plot representing the distribution of the given fieldmaps\n",
        "    labels: List of strings including fieldmaps label\n",
        "    fieldmaps: List of numpy arrays of fieldmaps in the same order as labels\n",
        "    output: Output folder to save the violin plot\n",
        "    mask: Numpy array of a Mask corresponding to the MRS voxel volume\n",
        "    \"\"\"\n",
        "    sns.set(font_scale=2)\n",
        "\n",
        "    output_path = os.path.join(source_dir, output)\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    if np.shape(mask)==np.shape(fieldmaps[0]):\n",
        "        dict_map_avg = {label: fieldmap[mask == 1] for label, fieldmap in zip(labels, fieldmaps)}\n",
        "    else:\n",
        "        dict_map_avg = {label: fieldmap for label, fieldmap in zip(labels, fieldmaps)}\n",
        "\n",
        "    def calculate_rmse(data):\n",
        "        mean = np.mean(data)\n",
        "        mse = np.mean(np.square(data - mean))\n",
        "        return np.round(np.sqrt(mse), 1)\n",
        "\n",
        "    dict_means = {key: np.round(np.mean(value), 1) for key, value in dict_map_avg.items()}\n",
        "    dict_stds = {key: np.round(np.std(value), 1) for key, value in dict_map_avg.items()}\n",
        "    dict_rmse = {key: calculate_rmse(value) for key, value in dict_map_avg.items()}\n",
        "\n",
        "    ax = sns.violinplot(data=list(dict_map_avg.values()))\n",
        "\n",
        "    for i, (key, mean) in enumerate(dict_means.items()):\n",
        "        mean_str = \"{:.1f}\".format(mean)\n",
        "        std_str = \"{:.1f}\".format(dict_stds[key])\n",
        "        rmse_str = \"{:.1f}\".format(dict_rmse[key])\n",
        "        ax.text(i + 0.05, mean , f\"Mean: {mean_str}\\nSD: {std_str}\\nRMSE: {rmse_str}\",\n",
        "                horizontalalignment='left', verticalalignment='bottom', fontsize=45 / len(dict_means))\n",
        "\n",
        "    ax.set_ylabel('Frequency [Hz]', fontsize=50 / len(dict_means), fontweight='bold')\n",
        "    ax.set_xticks(range(len(labels)))\n",
        "    ax.set_xticklabels(labels, fontsize=50 / len(dict_means), fontweight='bold')\n",
        "    ax.set_title(f\"{subject}: $\\Delta$B0 distribution within MRS voxel\", fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.tick_params(axis='y', labelsize=10)  # Adjust the labelsize as per your preference\n",
        "    plt.savefig(os.path.join(output_path, f\"{subject}_B0_distribution.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    return dict_stds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWQO-9gCkuYZ"
      },
      "source": [
        "### 6.2 Display the fieldmaps distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i42xT9qHlTJD"
      },
      "outputs": [],
      "source": [
        "all_Siemens_fmaps=[]\n",
        "all_Grad_fmaps=[]\n",
        "all_PI_fmaps=[]\n",
        "all_LSq_fmaps=[]\n",
        "all_QuadProg_fmaps=[]\n",
        "sd_field_maps = {}\n",
        "# Iterate over each subject\n",
        "for subject in subjects_list:\n",
        "    sd_field_maps[subject] = {}\n",
        "    derivative_path = current_path + f\"/derivatives/{subject}/\"\n",
        "    mask_mrs_nii = nib.load(derivative_path + 'mask_mrs.nii.gz')\n",
        "    mask_mrs = mask_mrs_nii.get_fdata()\n",
        "\n",
        "    fieldmap_Grad = nib.load (derivative_path + f\"fmap/static_shim_grad/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    fieldmap_PI = nib.load (derivative_path + f\"fmap/static_shim_pi/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    fieldmap_LSq= nib.load (derivative_path + f\"fmap/static_shim_lsq/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    fieldmap_QuadProg = nib.load (derivative_path + f\"fmap/static_shim_quadprog/fieldmap_calculated_shim.nii.gz\").get_fdata()\n",
        "    fieldmap_Siemens = nib.load (derivative_path + f\"fmap/{subject}_acq-siemens-fieldmap.nii.gz\").get_fdata()\n",
        "\n",
        "    all_Siemens_fmaps.append(fieldmap_Siemens[mask_mrs==1].flatten())\n",
        "    all_Grad_fmaps.append(fieldmap_Grad[mask_mrs==1].flatten())\n",
        "    all_PI_fmaps.append(fieldmap_PI[mask_mrs==1].flatten())\n",
        "    all_LSq_fmaps.append(fieldmap_LSq[mask_mrs==1].flatten())\n",
        "    all_QuadProg_fmaps.append(fieldmap_QuadProg[mask_mrs==1].flatten())\n",
        "\n",
        "\n",
        "    fmaps = [fieldmap_Siemens, fieldmap_PI, fieldmap_QuadProg, fieldmap_LSq, fieldmap_Grad]\n",
        "    labels = [\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"]\n",
        "    source_dir = os.getcwd()\n",
        "    output = derivative_path\n",
        "    sd = analyse_fieldmap(source_dir, labels, fmaps, output, mask_mrs, subject)\n",
        "    sd_field_maps[subject] =sd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3fFOLVOXKbc"
      },
      "outputs": [],
      "source": [
        "# Calculate standard deviation for each method across all subjects\n",
        "std_dict = {}\n",
        "for key in sd_field_maps['sub-1'].keys():\n",
        "    values = [sd_field_maps[sub][key] for sub in sd_field_maps]\n",
        "    std_dict[key] = np.round(np.std(values),1)\n",
        "\n",
        "print(\"Standard Deviation for Each method across all subjects:\")\n",
        "for key, value in std_dict.items():\n",
        "    print(f\"{key}: {value} Hz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYUy0Fo4kuYZ"
      },
      "outputs": [],
      "source": [
        "shim_methods=[\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"]\n",
        "for method in shim_methods:\n",
        "    # Create the variable name dynamically\n",
        "    var_name = f\"all_{method}_data\"\n",
        "\n",
        "    # Extract the data for the current method\n",
        "    data = locals()[f\"all_{method}_fmaps\"]\n",
        "    concat_data = np.concatenate(data)\n",
        "\n",
        "    # Assign the concat_data to the dynamically created variable\n",
        "    exec(f\"{var_name} = concat_data\")\n",
        "\n",
        "fmaps = [all_Siemens_data, all_PI_data, all_QuadProg_data, all_LSq_data, all_Grad_data]\n",
        "labels = shim_methods\n",
        "source_dir = os.getcwd()\n",
        "output = 'derivatives/All_subjects'\n",
        "subject = 'All subjects'\n",
        "distribution = analyse_fieldmap(source_dir, labels, fmaps, output, mask_mrs, subject)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxV_fOYkuYZ"
      },
      "source": [
        "### 6.3 Perform statistical test on fieldmaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHG45IZckuYa"
      },
      "source": [
        "By comparing the variance, the following cell assesses whether the distribution of each shimming method significantly differs from the Siemens shimming.\n",
        "The documentation for the following tests can be found [here](https://docs.scipy.org/doc/scipy-1.11.4/reference/generated/scipy.stats.shapiro.html) and [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqqyK-LVkuYa"
      },
      "outputs": [],
      "source": [
        "import statsmodels.stats.multitest as smm\n",
        "# Shapiro-Wilk test to check the normality of the reference distribution (Siemens shimming)\n",
        "statistic, p_value = stats.shapiro(all_Siemens_data)\n",
        "\n",
        "# Set significant level\n",
        "alpha = 0.01\n",
        "\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < alpha:\n",
        "    print('Reject the null hypothesis. The provided data does not follow a normal distribution.')\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The provided data may follow a normal distribution.\")\n",
        "\n",
        "comparison_methods= ['Grad', 'PI', 'LSq', 'QuadProg']\n",
        "Uncor_pvals = []\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data\")\n",
        "    statistic, p_value = stats.levene(all_Siemens_data, data)\n",
        "    Uncor_pvals.append(p_value)\n",
        "print(\"Uncorrected p-values are: \", Uncor_pvals)\n",
        "\n",
        "# Perform Multiple comparison correction with step-down method using Bonferroni adjustments\n",
        "Corrected_pvals = smm.multipletests(Uncor_pvals, alpha=0.01, method='holm', is_sorted=False, returnsorted=False)\n",
        "print(\"Corrected p-values are: \" , Corrected_pvals)\n",
        "\n",
        "for pval, method in zip(Corrected_pvals[1], comparison_methods):\n",
        "  if pval < 0.0001:\n",
        "    print(f\"Reject the null hypothesis. The variance between the Siemens and {method} groups are significantly different.\")\n",
        "  else:\n",
        "    print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the Siemens and {method} groups.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIJzw0oZkuYa"
      },
      "outputs": [],
      "source": [
        "# Comparing pi and quadprog to the grad method\n",
        "\n",
        "comparison_methods= ['PI', 'QuadProg']\n",
        "# levene test\n",
        "for method in comparison_methods:\n",
        "    data = eval(f\"all_{method}_data\")\n",
        "    statistic, p_value = stats.levene(all_Grad_data, data)\n",
        "\n",
        "    # Set significancy level\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Interpret the results\n",
        "    if p_value < alpha:\n",
        "        print(f\"Reject the null hypothesis. The variance between the gradient and {method} groups are significantly different.\")\n",
        "    else:\n",
        "        print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the gradient and {method} groups.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoncgGQzkuYa"
      },
      "outputs": [],
      "source": [
        "# Comparing pi and quadprog\n",
        "\n",
        "# levene test\n",
        "statistic, p_value = stats.levene(all_PI_data, all_QuadProg_data)\n",
        "\n",
        "# Set significancy level\n",
        "alpha = 0.01\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis. The variance between the PI and QuadProg groups are significantly different.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis. There is no significant difference in variances between the pi and quadprog groups.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyoZVUyblTJD"
      },
      "source": [
        "## 7. MRS analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edgU0UwLkuYa"
      },
      "source": [
        "###  7.1. Water removal and fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEz2anTYkuYb"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "subjects_list=$(find .  -type d -maxdepth 1 -name \"sub-*\")\n",
        "IFS=$'\\n' read -d '' -r -a subjects_array <<< \"$subjects_list\"\n",
        "echo \"subjects list are: $subjects_list\"\n",
        "\n",
        "path_derivatives=$(find . -type d -name derivatives)\n",
        "echo \"Derivatives path is: ${path_derivatives}\"\n",
        "\n",
        "for subject in \"${subjects_array[@]}\"; do\n",
        "    echo \"Analyzing subject: ${subject}\"\n",
        "    path_mrs=$(find ${subject} -type d -name mrs)\n",
        "    echo \"mrs path is: ${path_mrs}\"\n",
        "    path_t1=$(find ${subject} -type f -name *T1w.nii.gz)\n",
        "    echo \"T1 path is: ${path_t1}\"\n",
        "    sub_basename=$(basename \"${subject}\")\n",
        "    subject_derivatives=${path_derivatives}/${sub_basename}/mrs\n",
        "    echo \"${sub_basename} derivatives path is: ${subject_derivatives}\"\n",
        "\n",
        "    shim_methods=(\"siemens\" \"pi\" \"quadprog\" \"lsq\" \"grad\")\n",
        "    for method in \"${shim_methods[@]}\"; do\n",
        "        fsl_mrs_proc remove --file ${path_mrs}/${subject}_acq-press-${method}-shim_nuc-H_echo-135_svs.nii.gz --output ${subject_derivatives}/${method}_water_removed -r  --ppm 3.5 9\n",
        "        fsl_mrs  --data ${subject_derivatives}/${method}_water_removed/${subject}_acq-press-${method}-shim_nuc-H_echo-135_svs.nii.gz --basis ${path_derivatives}/LCModel_Siemens_UnEdited_PRESS_135_ALL.BASIS --t1 ${path_t1} --output ${subject_derivatives}/${method}_fit_result --report --algo MH --ppmlim 0 4.2  --no_conj_fid   --no_conj_basis  --TE 135\n",
        "    done\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF0j-YDBkuYb"
      },
      "source": [
        "### 7.2 Plot the fittings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_da0nkJkuYb"
      },
      "outputs": [],
      "source": [
        "# Iterate over each subject\n",
        "current_path = os.getcwd()\n",
        "index = 1\n",
        "plt.figure(figsize=(40, 40))\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "shim_methods=['siemens','pi' ,'quadprog' ,'lsq','grad']\n",
        "for subject in subjects_list:\n",
        "    for method in shim_methods:\n",
        "        fit_path = current_path + f\"/derivatives/{subject}/mrs/{method}_fit_result/\"\n",
        "        plt.subplot(len(subjects_list),len(shim_methods), index)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(plt.imread(fit_path + 'fit_summary.png'))\n",
        "        plt.title(f\" {subject}_{method}_shim\", fontsize=14)\n",
        "        index += 1\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.savefig(current_path + '/derivatives/All_subjects/mrs_fittings.png', dpi=300, bbox_inches='tight')\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOsM9FkgkuYb"
      },
      "source": [
        "### 7.3. Extract the metabolites fit results from the CSV files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbgG8qEXkuYb"
      },
      "outputs": [],
      "source": [
        "# Example path to the current directory\n",
        "current_path = os.getcwd()\n",
        "\n",
        "# Iterate over each subject and shim method to extract CRLB values\n",
        "crlb_NAA_all = {}\n",
        "crlb_CR_all = {}\n",
        "crlb_CHO_all = {}\n",
        "fwhm_NAA_all = {}\n",
        "snr_NAA_all = {}\n",
        "fwhm_CR_all = {}\n",
        "snr_CR_all = {}\n",
        "fwhm_CHO_all = {}\n",
        "snr_CHO_all = {}\n",
        "plt.figure(figsize=(20, 20))\n",
        "index = 1\n",
        "for subject in subjects_list:\n",
        "    crlb_NAA_all[subject] = {}\n",
        "    crlb_CR_all[subject] = {}\n",
        "    crlb_CHO_all[subject] = {}\n",
        "    fwhm_NAA_all[subject] = {}\n",
        "    snr_NAA_all[subject] = {}\n",
        "    fwhm_CR_all[subject] = {}\n",
        "    snr_CR_all[subject] = {}\n",
        "    fwhm_CHO_all[subject] = {}\n",
        "    snr_CHO_all[subject] = {}\n",
        "    for method in shim_methods:\n",
        "        fit_path = os.path.join(current_path, f\"derivatives/{subject}/mrs/{method}_fit_result/\")\n",
        "\n",
        "        # Read summary.csv file\n",
        "        summary_file_path = os.path.join(fit_path, 'summary.csv')\n",
        "        if os.path.exists(summary_file_path):\n",
        "            df = pd.read_csv(summary_file_path)\n",
        "            # if method == 'siemens':\n",
        "            #     print(df)\n",
        "\n",
        "            # Get the values for NAA, cr, cho\n",
        "            CRLB_Cr = df.at[2, '%CRLB']\n",
        "            crlb_CR_all[subject][method] = CRLB_Cr\n",
        "\n",
        "            CRLB_CHO = df.at[15, '%CRLB']\n",
        "            crlb_CHO_all[subject][method] = CRLB_CHO\n",
        "\n",
        "            CRLB_NAA = df.at[13, '%CRLB']\n",
        "            crlb_NAA_all[subject][method] = CRLB_NAA\n",
        "\n",
        "            fwhm_NAA = df.at[13, 'FWHM']\n",
        "            snr_NAA = df.at[13, 'SNR']\n",
        "            fwhm_NAA_all[subject][method] = fwhm_NAA\n",
        "            snr_NAA_all[subject][method] = snr_NAA\n",
        "\n",
        "            fwhm_CR = df.at[2, 'FWHM']\n",
        "            snr_CR = df.at[2, 'SNR']\n",
        "            fwhm_CR_all[subject][method] = fwhm_CR\n",
        "            snr_CR_all[subject][method] = snr_CR\n",
        "\n",
        "            fwhm_CHO = df.at[15, 'FWHM']\n",
        "            snr_CHO = df.at[15, 'SNR']\n",
        "            fwhm_CHO_all[subject][method] = fwhm_CHO\n",
        "            snr_CHO_all[subject][method] = snr_CHO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVF25dC0lTJF"
      },
      "source": [
        "### 7.4. Comparing metabolites' FWHM and SNR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewauhiqUkuYc"
      },
      "outputs": [],
      "source": [
        "metab_list= ['NAA', 'CR', 'CHO']\n",
        "# Create figure and axes\n",
        "fig, axs = plt.subplots(len(metab_list), 3, figsize=(18, 18))\n",
        "import matplotlib.markers as mmarkers\n",
        "\n",
        "# Define a horizontal line marker\n",
        "hline_marker = mmarkers.MarkerStyle('_')\n",
        "hline_marker._transform = hline_marker.get_transform().scale(5, 5)\n",
        "mean_fwhm_all = {}\n",
        "mean_snr_all = {}\n",
        "mean_crlb_all = {}\n",
        "for i, metab in enumerate(metab_list):\n",
        "    # Compute the mean values for FWHM and SNR for each metabolite\n",
        "    mean_fwhm = {key: np.round(np.mean([globals()[f'fwhm_{metab}_all'][sub][key] for sub in globals()[f'fwhm_{metab}_all']]), decimals=1) for key in globals()[f'fwhm_{metab}_all']['sub-1'].keys()}\n",
        "    mean_snr = {key: np.round(np.mean([globals()[f'snr_{metab}_all'][sub][key] for sub in globals()[f'snr_{metab}_all']]), decimals=1) for key in globals()[f'snr_{metab}_all']['sub-1'].keys()}\n",
        "    mean_crlb = {key: np.round(np.mean([globals()[f'crlb_{metab}_all'][sub][key] for sub in globals()[f'crlb_{metab}_all']]), decimals=1) for key in globals()[f'crlb_{metab}_all']['sub-1'].keys()}\n",
        "    mean_fwhm_all[metab] = mean_fwhm\n",
        "    mean_snr_all[metab] = mean_snr\n",
        "    mean_crlb_all[metab] = mean_crlb\n",
        "\n",
        "    # Plot FWHM\n",
        "    axs[i, 0].set_title(f\"FWHM (Hz) {metab}\", fontsize=18)\n",
        "    for sub in globals()[f'fwhm_{metab}_all']:\n",
        "        axs[i, 0].scatter(list(globals()[f'fwhm_{metab}_all'][sub].keys()), list(globals()[f'fwhm_{metab}_all'][sub].values()), label=sub)\n",
        "    axs[i, 0].scatter(list(mean_fwhm.keys()), list(mean_fwhm.values()), color='black', marker=hline_marker, label='mean')\n",
        "    axs[i, 0].legend(prop={'size': 15}, loc='upper right', bbox_to_anchor=(0.4, 1))\n",
        "    axs[i, 0].tick_params(axis='x', rotation=45, labelsize=14)\n",
        "    axs[i, 0].yaxis.set_minor_locator(plt.MultipleLocator(1))  # Set minor ticks for y-axis\n",
        "    axs[i, 0].grid(which='major', axis='y')\n",
        "\n",
        "    # Plot SNR\n",
        "    axs[i, 1].set_title(f\"SNR (A.U.) {metab}\", fontsize=18)\n",
        "    for sub in globals()[f'snr_{metab}_all']:\n",
        "        axs[i, 1].scatter(list(globals()[f'snr_{metab}_all'][sub].keys()), list(globals()[f'snr_{metab}_all'][sub].values()), label=sub)\n",
        "    axs[i, 1].scatter(list(mean_snr.keys()), list(mean_snr.values()), color='black', marker= hline_marker, label='mean')\n",
        "    axs[i, 1].legend(prop={'size': 15}, loc='upper right', bbox_to_anchor=(0.9, 1))\n",
        "    axs[i, 1].tick_params(axis='x', rotation=45, labelsize=14)\n",
        "    axs[i, 1].yaxis.set_minor_locator(plt.MultipleLocator(1))  # Set minor ticks for y-axis\n",
        "    axs[i, 1].grid(which='major', axis='y')\n",
        "\n",
        "\n",
        "    # Plot crlb\n",
        "    axs[i, 2].set_title(f\"CRLB (%) {metab}\", fontsize=18)\n",
        "    for sub in globals()[f'crlb_{metab}_all']:\n",
        "        axs[i, 2].scatter(list(globals()[f'crlb_{metab}_all'][sub].keys()), list(globals()[f'crlb_{metab}_all'][sub].values()), label=sub)\n",
        "    axs[i, 2].scatter(list(mean_crlb.keys()), list(mean_crlb.values()), color='black', marker= hline_marker, label='mean')\n",
        "    axs[i, 2].legend(prop={'size': 15}, loc='upper right', bbox_to_anchor=(0.5, 1))\n",
        "    axs[i, 2].tick_params(axis='x', rotation=45, labelsize=14)\n",
        "    axs[i, 2].yaxis.set_minor_locator(plt.MultipleLocator(1))  # Set minor ticks for y-axis\n",
        "    axs[i, 2].grid(which='major', axis='y')\n",
        "\n",
        "    # Set x tick labels\n",
        "    axs[i, 0].set_xticklabels([\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"])\n",
        "    axs[i, 1].set_xticklabels([\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"])\n",
        "    axs[i, 2].set_xticklabels([\"Siemens\", \"PI\", \"QuadProg\", \"LSq\", \"Grad\"])\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "plt.savefig(current_path + '/derivatives/All_subjects/FWHM_SNR_comparison.png', dpi=300, bbox_inches='tight')\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG21mJzQkuYc"
      },
      "source": [
        "### 7.5. Create a CSV output  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVBs4Dz5kuYc"
      },
      "outputs": [],
      "source": [
        "# Initialize lists for each criteria\n",
        "all_data_dicts_fwhm = []\n",
        "all_data_dicts_snr = []\n",
        "all_data_dicts_crlb = []\n",
        "current_path = os.getcwd()\n",
        "criteria_list = ['fwhm', 'snr', 'crlb']\n",
        "\n",
        "for criteria in criteria_list:\n",
        "    mean_criteria_all = globals()[f'mean_{criteria}_all']\n",
        "\n",
        "    # Calculate the percentage difference for each dictionary\n",
        "    percentage_diff_dict = {}\n",
        "    for metab, values in mean_criteria_all.items():\n",
        "        siemens_value = values['siemens']\n",
        "        percentage_diff = {}\n",
        "        for key, value in values.items():\n",
        "            if key != 'siemens':\n",
        "                percentage_diff[key] = ((value - siemens_value) / siemens_value) * 100\n",
        "        percentage_diff_dict[metab] = percentage_diff\n",
        "\n",
        "    # Concatenate the original data and the percentage difference data\n",
        "    for metab, values in mean_criteria_all.items():\n",
        "        combined_dict = {'metabolite': metab}\n",
        "        for key, value in values.items():\n",
        "            combined_dict[f'{key}'] = round(value, 1)  # Round to one decimal place\n",
        "            if key != 'siemens':\n",
        "                combined_dict[f'{key} change (%)'] = round(percentage_diff_dict[metab].get(key, None), 1)  # Round to one decimal place\n",
        "        if criteria == 'fwhm':\n",
        "            all_data_dicts_fwhm.append(combined_dict)\n",
        "        elif criteria == 'snr':\n",
        "            all_data_dicts_snr.append(combined_dict)\n",
        "        elif criteria == 'crlb':\n",
        "            all_data_dicts_crlb.append(combined_dict)\n",
        "\n",
        "# Create DataFrames for each criteria\n",
        "df_fwhm = pd.DataFrame(all_data_dicts_fwhm)\n",
        "df_snr = pd.DataFrame(all_data_dicts_snr)\n",
        "df_crlb = pd.DataFrame(all_data_dicts_crlb)\n",
        "# Display the DataFrames\n",
        "df_fwhm_styled = df_fwhm.style.set_table_styles([{'selector': 'th', 'props': [('background', '#f7f7f9'), ('color', 'black'), ('border', '1px solid #dee2e6')]}])\n",
        "df_fwhm_formatted = df_fwhm.apply(lambda x: x.apply(lambda y: '{:.1f}'.format(y) if isinstance(y, float) else y))\n",
        "\n",
        "df_snr_styled = df_snr.style.set_table_styles([{'selector': 'th', 'props': [('background', '#f7f7f9'), ('color', 'black'), ('border', '1px solid #dee2e6')]}])\n",
        "df_snr_formatted = df_snr.apply(lambda x: x.apply(lambda y: '{:.1f}'.format(y) if isinstance(y, float) else y))\n",
        "\n",
        "df_crlb_styled = df_crlb.style.set_table_styles([{'selector': 'th', 'props': [('background', '#f7f7f9'), ('color', 'black'), ('border', '1px solid #dee2e6')]}])\n",
        "df_crlb_formatted = df_crlb.apply(lambda x: x.apply(lambda y: '{:.1f}'.format(y) if isinstance(y, float) else y))\n",
        "\n",
        "# Display the styled DataFrames\n",
        "print(\"FWHM DataFrame:\")\n",
        "display(df_fwhm_formatted)\n",
        "\n",
        "print(\"SNR DataFrame:\")\n",
        "display(df_snr_formatted)\n",
        "\n",
        "print(\"CRLB DataFrame:\")\n",
        "display(df_crlb_formatted)\n",
        "\n",
        "separator_row_snr = pd.DataFrame({'metabolite': ['SNR']})\n",
        "separator_row_crlb = pd.DataFrame({'metabolite': ['CRLB']})\n",
        "# Create a separator row with repeated column names\n",
        "separator_row_columns = pd.DataFrame([df_fwhm_formatted.columns], columns=df_fwhm_formatted.columns)\n",
        "\n",
        "# Concatenate the DataFrames with the separator rows\n",
        "combined_df = pd.concat([ df_fwhm_formatted, separator_row_snr, separator_row_columns, df_snr_formatted, separator_row_crlb, separator_row_columns,df_crlb_formatted], axis=0)\n",
        "\n",
        "# Save the combined DataFrame to a CSV file\n",
        "combined_df.to_csv(current_path + '/derivatives/All_subjects/Metabolites_fit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Phs6gCJ1lTI_",
        "O0IDwpEwlTJA",
        "NEuAWZjBlTJB",
        "7ovVOFv1ve2J",
        "KyXMxQD_kuYY",
        "QWQO-9gCkuYZ",
        "OWxV_fOYkuYZ",
        "edgU0UwLkuYa",
        "UF0j-YDBkuYb",
        "qOsM9FkgkuYb",
        "AVF25dC0lTJF",
        "mG21mJzQkuYc"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}